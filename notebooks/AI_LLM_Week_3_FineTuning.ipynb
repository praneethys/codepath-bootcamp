{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwnELfJpgSJQ"
      },
      "source": [
        "# AI/LLM for Devs, Week 3 Experiment notebook\n",
        "\n",
        "This notebook captures a series of experiments to create high quality and effective training sets for fine-tuning LLMs on knowledge.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq-ww00eg1uh"
      },
      "source": [
        "## Experiment #1 - Training a series of facts\n",
        "\n",
        "The purpose of this experiment is to explore teaching GPT-3.5 Turbo a series of facts via fine-tuning, and rate its performance and level of hallucination.\n",
        "\n",
        "### Step 1: Choose 10 facts\n",
        "\n",
        "Choose a topic that ChatGPT doesn't already know, such as your personal history, your company, or some niche topic.\n",
        "\n",
        "1. Praneeth Yerrapragada is studying spoken Sanskrit language from Samskrita Bharati USA.\n",
        "2. Praneeth Yerrapragada has hiked to the top of Half Dome in Yosemite in 2017.\n",
        "3. Praneeth Yerrapragada graduated from the University of Southern California majoring in Electrical / Computer Engineering in 2014.\n",
        "4. Praneeth Yerrapragada has a wife and two children.\n",
        "5. Praneeth Yerrapragada has lived in Los Angeles, California.\n",
        "6. Praneeth Yerrapragada has travelled to Antarctica in 2017.\n",
        "7. Praneeth Yerrapragada was born in Hyderabad, India.\n",
        "8. Praneeth Yerrapragada practices Yoga and Meditation regularly.\n",
        "9. Praneeth Yerrapragada's parents live in Hyderabad, India.\n",
        "10. Praneeth Yerrapragada loves to spend time with his family.\n",
        "\n",
        "### Step 2: Design your evaluation questions\n",
        "\n",
        "Enumerate 10 questions below. Start with straightforward questions that are close to the core facts, then expand to contextually related questions, then out-of-scope questions. These questions will be your performance benchmark.\n",
        "\n",
        "1. Where did Praneeth Yerrapragada graduate from?\n",
        "2. What was Praneeth Yerrapragada's major?\n",
        "3. What does Praneeth Yerrapragada love to do?\n",
        "4. How many children does Praneeth Yerrapragada have?\n",
        "5. What was Praneeth Yerrapragada's favorite hobby?\n",
        "6. Does Praneeth Yerrapragada like to travel?\n",
        "7. Where is Praneeth Yerrapragada from?\n",
        "8. Is Praneeth Yerrapragada married?\n",
        "9. Is Praneeth Yerrapragada a happy individual?\n",
        "10. What does Praneeth Yerrapragada likes to eat?\n",
        "\n",
        "### Step 3: Generate your initial training set\n",
        "\n",
        "Generate a naive training set, using something like the prompt below. Start by generating 3 question/response pairs for each fact.\n",
        "\n",
        "```\n",
        "Based on the following fact, generate an array of {n} variations of question-answer pairs.\n",
        "Each pair should be formatted as a JSON object with \"messages\" containing \"user\" and \"assistant\" roles.\n",
        "Ensure that the output is in JSON format.\n",
        "\n",
        "Each question should be unique, clearly phrased, and reflect how users might ask about this fact.\n",
        "The corresponding answer should be accurate, contextually relevant, and phrased differently from the other answers.\n",
        "Ensure diversity in question types (who, what, where, when, why) and avoid repetitive phrasing.\n",
        "\n",
        "Fact: \"{fact}\"\n",
        "\n",
        "Example output format:\n",
        "\n",
        "{{\"data\": [{{\"messages\": [{{\"role\": \"user\", \"content\": \"What is the capital of France?\"}}, {{\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}}]}},\n",
        "{{\"messages\": [{{\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}}, {{\"role\": \"assistant\", \"content\": \"The author of 'Romeo and Juliet' is William Shakespeare.\"}}]}},\n",
        "{{\"messages\": [{{\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}}, {{\"role\": \"assistant\", \"content\": \"The distance from the Moon to Earth is approximately 384,400 kilometers.\"}}]}}]\n",
        "}}\n",
        "```\n",
        "\n",
        "Reference the code block for a snippet that will pass this prompt to the OpenAI API. Note: add a $5 credit to your the OpenAI platform: https://platform.openai.com/settings/organization/billing/overview\n",
        "\n",
        "### Step 4: Create a GPT-3.5 Turbo fine-tuned model\n",
        "\n",
        "Use the web interface to add your training and validation data: https://platform.openai.com/finetune\n",
        "\n",
        "Initially, use the default hyperparameters.\n",
        "\n",
        "### Step 5: Evaluation\n",
        "\n",
        "Ask the evaluation questions you created in Step 2, and note accuracy, hallucination, and overfitting.\n",
        "\n",
        "### Step 6: Improving quality\n",
        "\n",
        "For each issue you discovered in Step 5, create additional training data to address the issue.\n",
        "\n",
        "- Create new prompts to expand your training data\n",
        "- Manually review and fix or delete bad training data\n",
        "\n",
        "Improvements will mostly be made through improving the training data, but also run the following variations:\n",
        "\n",
        "- Cut your training data in half, and compare results. That is a predictor for the increase in quality if you double your training data.\n",
        "- If the model isn't learning your data, try increasing your epochs by 1 or 2\n",
        "- If the model is overfitting, try reducing your epochs by 1 or 2\n",
        "- Try halfing and doubling your epochs to explore those effects\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Were you able to train on the additional facts, while minimizing hallucination? (you'll never fully eliminate hallucination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKTi8cUQKY5D"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "facts = []\n",
        "with open('data/facts.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        facts.append(json.loads(line))\n",
        "\n",
        "client = OpenAI(api_key='YOUR_API_KEY_HERE')\n",
        "\n",
        "def generate_qa(fact, n=20):\n",
        "    prompt_text = f\"\"\"\n",
        "    Based on the following fact, generate an array of {n} variations of question-answer pairs.\n",
        "    Each pair should be formatted as a JSON object with \"messages\" containing \"user\" and \"assistant\" roles.\n",
        "    Ensure that the output is in JSON format.\n",
        "\n",
        "    Each question should be unique, clearly phrased, and reflect how users might ask about this fact.\n",
        "    The corresponding answer should be accurate, contextually relevant, and phrased differently from the other answers.\n",
        "    Ensure diversity in question types (who, what, where, when, why) and avoid repetitive phrasing.\n",
        "\n",
        "    Fact: \"{fact}\"\n",
        "\n",
        "    Example output format:\n",
        "\n",
        "    {{\"data\": [{{\"messages\": [{{\"role\": \"user\", \"content\": \"What is the capital of France?\"}}, {{\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}}]}},\n",
        "    {{\"messages\": [{{\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}}, {{\"role\": \"assistant\", \"content\": \"The author of 'Romeo and Juliet' is William Shakespeare.\"}}]}},\n",
        "    {{\"messages\": [{{\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}}, {{\"role\": \"assistant\", \"content\": \"The distance from the Moon to Earth is approximately 384,400 kilometers.\"}}]}}]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant tasked with generating training data for fine-tuning a gpt-3.5-turbo model in JSON format\"},\n",
        "            {\"role\": \"user\", \"content\": prompt_text}\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content.strip())\n",
        "    try:\n",
        "        qa_array = json.loads(response.choices[0].message.content.strip())[\"data\"]\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Failed to decode JSON:\", e)\n",
        "        return [], []\n",
        "\n",
        "    # Splitting the generated QA pairs into training and validation sets\n",
        "    validation_size = int(len(qa_array) * 0.2)\n",
        "    validation_set = qa_array[:validation_size]\n",
        "    training_set = qa_array[validation_size:]\n",
        "\n",
        "    return training_set, validation_set\n",
        "\n",
        "\n",
        "training_set = []\n",
        "validation_set = []\n",
        "\n",
        "for fact in facts:\n",
        "    training, validation = generate_qa(fact['fact'])\n",
        "    training_set.extend(training)\n",
        "    validation_set.extend(validation)\n",
        "\n",
        "with open('data/facts_training.jsonl', 'w') as train_outfile:\n",
        "    for qa in training_set:\n",
        "        train_outfile.write(json.dumps(qa) + '\\n')\n",
        "\n",
        "with open('data/facts_validation.jsonl', 'w') as valid_outfile:\n",
        "    for qa in validation_set:\n",
        "        valid_outfile.write(json.dumps(qa) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xS2mKRZKmXj"
      },
      "source": [
        "## Experiment #2 - Group project training data\n",
        "\n",
        "Assemble initial training data for your group project. For example, identify potential use cases, such as:\n",
        "\n",
        "- Additional app or domain-specific knowledge\n",
        "- Behavioral modification\n",
        "- Tool usage\n",
        "\n",
        "If your task is behavioral modification or tool usage, do the following steps:\n",
        "\n",
        "1. Design a detailed prompt describing the desired behavior, or usage of the tool\n",
        "2. Use the prompt in real situations on GPT-4o\n",
        "3. Create training data by:\n",
        "   - Loading in the original prompt as a system message, and a brief context of the conversation\n",
        "   - Add snippets of the recorded conversation\n",
        "4. Start with 5 \"real\" interactions, and evaluate the model peformance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7PAONVTMytZ"
      },
      "source": [
        "## Experiment #3 (optional) - Training a 10-page document\n",
        "\n",
        "Choose a 10-page document (ideally a text or markdown file for easier initial parsing).\n",
        "\n",
        "1. Start by generating question/answer pairs for document semantic (or non-semantic chunks)\n",
        "2. Use a prompt to create a detailed summary of the document, and generate question/answer pairs based on the summary.\n",
        "3. Use a prompt to contain what sections do and do not cover, to hopefully mitigate hallucination\n",
        "\n",
        "Create a set of evaluation questions (separate from the validation set). Evaluate the performance between each of the stages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvK_G2whX5QY"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Submit your experiment notebook [in the form here](https://forms.gle/DKeRAuYkvDQGjs9P9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx-X4LlNOcPd"
      },
      "source": [
        "## Appendix\n",
        "\n",
        "The code below was and expanded version of the trivia code, which injects a system message into each piece of training data, and also generates boundary pairs to help define the scope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxTJY0MBOqxp"
      },
      "outputs": [],
      "source": [
        "# This notebook generates training data for fine-tuning gpt3.5-turbo on an array of facts\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "facts = []\n",
        "with open('data/facts.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        facts.append(json.loads(line))\n",
        "\n",
        "client = OpenAI(api_key='YOUR API KEY')\n",
        "\n",
        "def generate_qa(fact, n=10):\n",
        "    prompt_text = f\"\"\"\n",
        "    Based on the following fact, generate an array of {n} variations of question-answer pairs.\n",
        "    Each pair should be formatted as a JSON object with \"messages\" containing \"user\" and \"assistant\" roles.\n",
        "    Ensure that the output is in JSON format.\n",
        "\n",
        "    Each question should be unique, clearly phrased, and reflect how users might ask about this fact.\n",
        "    The corresponding answer should be accurate, contextually relevant, and phrased differently from the other answers.\n",
        "    Ensure diversity in question types (who, what, where, when, why) and avoid repetitive phrasing.\n",
        "\n",
        "    Fact: \"{fact}\"\n",
        "\n",
        "    Example output format:\n",
        "\n",
        "    {{\"data\": [{{\"messages\": [{{\"role\": \"user\", \"content\": \"What is the capital of France?\"}}, {{\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}}]}},\n",
        "    {{\"messages\": [{{\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}}, {{\"role\": \"assistant\", \"content\": \"The author of 'Romeo and Juliet' is William Shakespeare.\"}}]}},\n",
        "    {{\"messages\": [{{\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}}, {{\"role\": \"assistant\", \"content\": \"The distance from the Moon to Earth is approximately 384,400 kilometers.\"}}]}}]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_pairs(prompt_text, n)\n",
        "\n",
        "def generate_boundaries(facts, n=40):\n",
        "    prompt_text = f\"\"\"\n",
        "    Based on the following facts, generate an array of {n} variations of question-answer pairs.\n",
        "    Each pair should be formatted as a JSON object with \"messages\" containing \"user\" and \"assistant\" roles.\n",
        "    Ensure that the output is in JSON format.\n",
        "\n",
        "    The question-answer pairs should establish boundaries of what the assistant knows beyond the facts below.\n",
        "    Pairs should use mostly negative examples to establish the boundaries of the facts. For example,\n",
        "    pairs should include negative examples of detailed followup questions beyond the scope of the facts.\n",
        "\n",
        "    For each fact, imagine reasonable followup questions that might be asked by a user, and decline to answer. Add\n",
        "    your rationale in the \"rationale\" key.\n",
        "\n",
        "    Facts: {facts}\n",
        "\n",
        "    Example output format:\n",
        "\n",
        "    {{\"data\": [{{\"messages\": [{{\"role\": \"user\", \"content\": \"What is the capital of France?\"}}, {{\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}}]}},\n",
        "    {{\"messages\": [{{\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}}, {{\"role\": \"assistant\", \"content\": \"The author of 'Romeo and Juliet' is William Shakespeare.\"}}]}},\n",
        "    {{\"messages\": [{{\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}}, {{\"role\": \"assistant\", \"content\": \"The distance from the Moon to Earth is approximately 384,400 kilometers.\"}}]}}]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_pairs(prompt_text, n)\n",
        "\n",
        "def generate_pairs(prompt_text, n=10):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant tasked with generating training data for fine-tuning a gpt-3.5-turbo model in JSON format\"},\n",
        "            {\"role\": \"user\", \"content\": prompt_text}\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content.strip())\n",
        "    try:\n",
        "        qa_array = [{\"messages\": item[\"messages\"]} for item in json.loads(response.choices[0].message.content.strip())[\"data\"]]\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Failed to decode JSON:\", e)\n",
        "        return [], []\n",
        "\n",
        "    # Splitting the generated QA pairs into training and validation sets\n",
        "    validation_size = int(len(qa_array) * 0.2)\n",
        "    validation_set = qa_array[:validation_size]\n",
        "    training_set = qa_array[validation_size:]\n",
        "\n",
        "    return training_set, validation_set\n",
        "\n",
        "\n",
        "training_set = []\n",
        "validation_set = []\n",
        "\n",
        "for fact in facts:\n",
        "    training, validation = generate_qa(fact['fact'])\n",
        "    training_set.extend(training)\n",
        "    validation_set.extend(validation)\n",
        "\n",
        "facts_string = \"\\n\".join([fact['fact'] for fact in facts])\n",
        "training, validation = generate_boundaries(facts_string)\n",
        "training_set.extend(training)\n",
        "validation_set.extend(validation)\n",
        "\n",
        "# Inject a system message as the first message in the training and validation sets\n",
        "for qa in training_set:\n",
        "    qa['messages'].insert(0, {\"role\": \"system\", \"content\": \"You are an internal knowledge chat bot for CodePath, an education company\"})\n",
        "for qa in validation_set:\n",
        "    qa['messages'].insert(0, {\"role\": \"system\", \"content\": \"You are an internal knowledge chat bot for CodePath, an education company\"})\n",
        "\n",
        "with open('data/facts_training_2.jsonl', 'w') as train_outfile:\n",
        "    for qa in training_set:\n",
        "        train_outfile.write(json.dumps(qa) + '\\n')\n",
        "\n",
        "with open('data/facts_validation_2.jsonl', 'w') as valid_outfile:\n",
        "    for qa in validation_set:\n",
        "        valid_outfile.write(json.dumps(qa) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNlFj9wMX21k"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
